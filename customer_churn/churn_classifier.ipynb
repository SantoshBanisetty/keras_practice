{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict customer churn from bank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (10000, 14)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "print(type(dataset), dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RowNumber  CustomerId         Surname  CreditScore Geography  Gender  \\\n",
      "0             1    15634602        Hargrave          619    France  Female   \n",
      "1             2    15647311            Hill          608     Spain  Female   \n",
      "2             3    15619304            Onio          502    France  Female   \n",
      "3             4    15701354            Boni          699    France  Female   \n",
      "4             5    15737888        Mitchell          850     Spain  Female   \n",
      "5             6    15574012             Chu          645     Spain    Male   \n",
      "6             7    15592531        Bartlett          822    France    Male   \n",
      "7             8    15656148          Obinna          376   Germany  Female   \n",
      "8             9    15792365              He          501    France    Male   \n",
      "9            10    15592389              H?          684    France    Male   \n",
      "10           11    15767821          Bearce          528    France    Male   \n",
      "11           12    15737173         Andrews          497     Spain    Male   \n",
      "12           13    15632264             Kay          476    France  Female   \n",
      "13           14    15691483            Chin          549    France  Female   \n",
      "14           15    15600882           Scott          635     Spain  Female   \n",
      "15           16    15643966         Goforth          616   Germany    Male   \n",
      "16           17    15737452           Romeo          653   Germany    Male   \n",
      "17           18    15788218       Henderson          549     Spain  Female   \n",
      "18           19    15661507         Muldrow          587     Spain    Male   \n",
      "19           20    15568982             Hao          726    France  Female   \n",
      "20           21    15577657        McDonald          732    France    Male   \n",
      "21           22    15597945        Dellucci          636     Spain  Female   \n",
      "22           23    15699309       Gerasimov          510     Spain  Female   \n",
      "23           24    15725737          Mosman          669    France    Male   \n",
      "24           25    15625047             Yen          846    France  Female   \n",
      "25           26    15738191         Maclean          577    France    Male   \n",
      "26           27    15736816           Young          756   Germany    Male   \n",
      "27           28    15700772         Nebechi          571    France    Male   \n",
      "28           29    15728693      McWilliams          574   Germany  Female   \n",
      "29           30    15656300        Lucciano          411    France    Male   \n",
      "...         ...         ...             ...          ...       ...     ...   \n",
      "9970       9971    15587133        Thompson          518    France    Male   \n",
      "9971       9972    15721377            Chou          833    France  Female   \n",
      "9972       9973    15747927           Ch'in          758    France    Male   \n",
      "9973       9974    15806455          Miller          611    France    Male   \n",
      "9974       9975    15695474          Barker          583    France    Male   \n",
      "9975       9976    15666295           Smith          610   Germany    Male   \n",
      "9976       9977    15656062         Azikiwe          637    France  Female   \n",
      "9977       9978    15579969         Mancini          683    France  Female   \n",
      "9978       9979    15703563           P'eng          774    France    Male   \n",
      "9979       9980    15692664          Diribe          677    France  Female   \n",
      "9980       9981    15719276            T'ao          741     Spain    Male   \n",
      "9981       9982    15672754        Burbidge          498   Germany    Male   \n",
      "9982       9983    15768163         Griffin          655   Germany  Female   \n",
      "9983       9984    15656710           Cocci          613    France    Male   \n",
      "9984       9985    15696175  Echezonachukwu          602   Germany    Male   \n",
      "9985       9986    15586914          Nepean          659    France    Male   \n",
      "9986       9987    15581736        Bartlett          673   Germany    Male   \n",
      "9987       9988    15588839         Mancini          606     Spain    Male   \n",
      "9988       9989    15589329         Pirozzi          775    France    Male   \n",
      "9989       9990    15605622        McMillan          841     Spain    Male   \n",
      "9990       9991    15798964      Nkemakonam          714   Germany    Male   \n",
      "9991       9992    15769959     Ajuluchukwu          597    France  Female   \n",
      "9992       9993    15657105     Chukwualuka          726     Spain    Male   \n",
      "9993       9994    15569266          Rahman          644    France    Male   \n",
      "9994       9995    15719294            Wood          800    France  Female   \n",
      "9995       9996    15606229        Obijiaku          771    France    Male   \n",
      "9996       9997    15569892       Johnstone          516    France    Male   \n",
      "9997       9998    15584532             Liu          709    France  Female   \n",
      "9998       9999    15682355       Sabbatini          772   Germany    Male   \n",
      "9999      10000    15628319          Walker          792    France  Female   \n",
      "\n",
      "      Age  Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0      42       2       0.00              1          1               1   \n",
      "1      41       1   83807.86              1          0               1   \n",
      "2      42       8  159660.80              3          1               0   \n",
      "3      39       1       0.00              2          0               0   \n",
      "4      43       2  125510.82              1          1               1   \n",
      "5      44       8  113755.78              2          1               0   \n",
      "6      50       7       0.00              2          1               1   \n",
      "7      29       4  115046.74              4          1               0   \n",
      "8      44       4  142051.07              2          0               1   \n",
      "9      27       2  134603.88              1          1               1   \n",
      "10     31       6  102016.72              2          0               0   \n",
      "11     24       3       0.00              2          1               0   \n",
      "12     34      10       0.00              2          1               0   \n",
      "13     25       5       0.00              2          0               0   \n",
      "14     35       7       0.00              2          1               1   \n",
      "15     45       3  143129.41              2          0               1   \n",
      "16     58       1  132602.88              1          1               0   \n",
      "17     24       9       0.00              2          1               1   \n",
      "18     45       6       0.00              1          0               0   \n",
      "19     24       6       0.00              2          1               1   \n",
      "20     41       8       0.00              2          1               1   \n",
      "21     32       8       0.00              2          1               0   \n",
      "22     38       4       0.00              1          1               0   \n",
      "23     46       3       0.00              2          0               1   \n",
      "24     38       5       0.00              1          1               1   \n",
      "25     25       3       0.00              2          0               1   \n",
      "26     36       2  136815.64              1          1               1   \n",
      "27     44       9       0.00              2          0               0   \n",
      "28     43       3  141349.43              1          1               1   \n",
      "29     29       0   59697.17              2          1               1   \n",
      "...   ...     ...        ...            ...        ...             ...   \n",
      "9970   42       7  151027.05              2          1               0   \n",
      "9971   34       3  144751.81              1          0               0   \n",
      "9972   26       4  155739.76              1          1               0   \n",
      "9973   27       7       0.00              2          1               1   \n",
      "9974   33       7  122531.86              1          1               0   \n",
      "9975   50       1  113957.01              2          1               0   \n",
      "9976   33       7  103377.81              1          1               0   \n",
      "9977   32       9       0.00              2          1               1   \n",
      "9978   40       9   93017.47              2          1               0   \n",
      "9979   58       1   90022.85              1          0               1   \n",
      "9980   35       6   74371.49              1          0               0   \n",
      "9981   42       3  152039.70              1          1               1   \n",
      "9982   46       7  137145.12              1          1               0   \n",
      "9983   40       4       0.00              1          0               0   \n",
      "9984   35       7   90602.42              2          1               1   \n",
      "9985   36       6  123841.49              2          1               0   \n",
      "9986   47       1  183579.54              2          0               1   \n",
      "9987   30       8  180307.73              2          1               1   \n",
      "9988   30       4       0.00              2          1               0   \n",
      "9989   28       4       0.00              2          1               1   \n",
      "9990   33       3   35016.60              1          1               0   \n",
      "9991   53       4   88381.21              1          1               0   \n",
      "9992   36       2       0.00              1          1               0   \n",
      "9993   28       7  155060.41              1          1               0   \n",
      "9994   29       2       0.00              2          0               0   \n",
      "9995   39       5       0.00              2          1               0   \n",
      "9996   35      10   57369.61              1          1               1   \n",
      "9997   36       7       0.00              1          0               1   \n",
      "9998   42       3   75075.31              2          1               0   \n",
      "9999   28       4  130142.79              1          1               0   \n",
      "\n",
      "      EstimatedSalary  Exited  \n",
      "0           101348.88       1  \n",
      "1           112542.58       0  \n",
      "2           113931.57       1  \n",
      "3            93826.63       0  \n",
      "4            79084.10       0  \n",
      "5           149756.71       1  \n",
      "6            10062.80       0  \n",
      "7           119346.88       1  \n",
      "8            74940.50       0  \n",
      "9            71725.73       0  \n",
      "10           80181.12       0  \n",
      "11           76390.01       0  \n",
      "12           26260.98       0  \n",
      "13          190857.79       0  \n",
      "14           65951.65       0  \n",
      "15           64327.26       0  \n",
      "16            5097.67       1  \n",
      "17           14406.41       0  \n",
      "18          158684.81       0  \n",
      "19           54724.03       0  \n",
      "20          170886.17       0  \n",
      "21          138555.46       0  \n",
      "22          118913.53       1  \n",
      "23            8487.75       0  \n",
      "24          187616.16       0  \n",
      "25          124508.29       0  \n",
      "26          170041.95       0  \n",
      "27           38433.35       0  \n",
      "28          100187.43       0  \n",
      "29           53483.21       0  \n",
      "...               ...     ...  \n",
      "9970        119377.36       0  \n",
      "9971        166472.81       0  \n",
      "9972        171552.02       0  \n",
      "9973        157474.10       0  \n",
      "9974         13549.24       0  \n",
      "9975        196526.55       1  \n",
      "9976         84419.78       0  \n",
      "9977         24991.92       0  \n",
      "9978        191608.97       0  \n",
      "9979          2988.28       0  \n",
      "9980         99595.67       0  \n",
      "9981         53445.17       1  \n",
      "9982        115146.40       1  \n",
      "9983        151325.24       0  \n",
      "9984         51695.41       0  \n",
      "9985         96833.00       0  \n",
      "9986         34047.54       0  \n",
      "9987          1914.41       0  \n",
      "9988         49337.84       0  \n",
      "9989        179436.60       0  \n",
      "9990         53667.08       0  \n",
      "9991         69384.71       1  \n",
      "9992        195192.40       0  \n",
      "9993         29179.52       0  \n",
      "9994        167773.55       0  \n",
      "9995         96270.64       0  \n",
      "9996        101699.77       0  \n",
      "9997         42085.58       1  \n",
      "9998         92888.52       1  \n",
      "9999         38190.78       0  \n",
      "\n",
      "[10000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ..., 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ..., 0 1 112542.58]\n",
      " [502 'France' 'Female' ..., 1 0 113931.57]\n",
      " ..., \n",
      " [709 'France' 'Female' ..., 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ..., 1 0 92888.52]\n",
      " [792 'France' 'Female' ..., 1 0 38190.78]]\n",
      "[1 0 1 ..., 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelencoder_x1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_x1.fit_transform(X[:, 1])\n",
    "labelencoder_x2 = LabelEncoder()\n",
    "X[:,2] = labelencoder_x2.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features=[1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "churn_classifer = Sequential()\n",
    "churn_classifer.add(Dense(6, kernel_initializer='uniform', activation='relu', input_dim = 11))\n",
    "\n",
    "churn_classifer.add(Dense(6, kernel_initializer='uniform', activation='relu'))\n",
    "churn_classifer.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "churn_classifer.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 6s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 4s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 4s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 4s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 4s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 3s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 4s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 4s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 4s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 4s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 6s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 7s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 6s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 4s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 4s - loss: 0.5060 - acc: 0.7960     \n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 4s - loss: 0.5059 - acc: 0.7960     \n",
      "Epoch 40/100\n",
      "5760/8000 [====================>.........] - ETA: 1s - loss: 0.5059 - acc: 0.7960"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-80501f6f8f47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchurn_classifer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "churn_classifer.fit(X_train, y_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(6, kernel_initializer='uniform', activation='relu', input_dim = 11))\n",
    "    classifier.add(Dense(6, kernel_initializer='uniform', activation='relu'))\n",
    "    classifier.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "    classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4999 - acc: 0.7958     \n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4295 - acc: 0.7971     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4237 - acc: 0.7989     \n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4181 - acc: 0.8229     \n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4124 - acc: 0.8276     \n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4090 - acc: 0.8326     \n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4065 - acc: 0.8311     \n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4040 - acc: 0.8354     \n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4026 - acc: 0.8344     \n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4017 - acc: 0.8347     \n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4002 - acc: 0.8362     \n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3996 - acc: 0.8324     \n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3984 - acc: 0.8331     \n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3986 - acc: 0.8356     \n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3980 - acc: 0.8354     \n",
      "Epoch 16/100\n",
      "5860/7200 [=======================>......] - ETA: 0s - loss: 0.3908 - acc: 0.8401"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9bfac5f84854>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m    117\u001b[0m            (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3942\u001b[0m     \"\"\"\n\u001b[1;32m   3943\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3944\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3945\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3946\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \"\"\"\n\u001b[0;32m-> 3828\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3829\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3830\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/santosh/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers import Dropout\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(6, kernel_initializer='uniform', activation='relu', input_dim = 11))\n",
    "    classifier.add(Dropout(0.1))\n",
    "    classifier.add(Dense(6, kernel_initializer='uniform', activation='relu'))\n",
    "    classifier.add(Dropout(0.1))\n",
    "    classifier.add(Dense(6, kernel_initializer='uniform', activation='relu'))\n",
    "    classifier.add(Dropout(0.1))\n",
    "    classifier.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "    classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4884 - acc: 0.7962     \n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4396 - acc: 0.7971     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4329 - acc: 0.7971     \n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4304 - acc: 0.7971     \n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4295 - acc: 0.7971     \n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4290 - acc: 0.7971     \n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4258 - acc: 0.8032     \n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4270 - acc: 0.8181     \n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4284 - acc: 0.8267     \n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4306 - acc: 0.8257     \n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4300 - acc: 0.8228     \n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4273 - acc: 0.8242     \n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4264 - acc: 0.8240     \n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4250 - acc: 0.8250     \n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4286 - acc: 0.8264     \n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4287 - acc: 0.8274     \n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4268 - acc: 0.8260     \n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4268 - acc: 0.8256     \n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4289 - acc: 0.8275     \n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4226 - acc: 0.8264     \n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4268 - acc: 0.8262     \n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4298 - acc: 0.8264     \n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4238 - acc: 0.8268     \n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4259 - acc: 0.8300     \n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4272 - acc: 0.8294     \n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - ETA: 0s - loss: 0.4252 - acc: 0.826 - 4s - loss: 0.4250 - acc: 0.8265     \n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4240 - acc: 0.8296     \n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4289 - acc: 0.8282     \n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4246 - acc: 0.8308     \n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4263 - acc: 0.8296     \n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4256 - acc: 0.8292     \n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4252 - acc: 0.8299     \n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4260 - acc: 0.8269     \n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4242 - acc: 0.8292     - ETA: 0s - loss: 0.42\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4261 - acc: 0.8282     \n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4254 - acc: 0.8300     \n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4246 - acc: 0.8290     \n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4244 - acc: 0.8290     \n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4251 - acc: 0.8286     \n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4232 - acc: 0.8324     \n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4239 - acc: 0.8287     \n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4263 - acc: 0.8283     \n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4264 - acc: 0.8283     \n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4211 - acc: 0.8300     \n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4220 - acc: 0.8315     \n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4254 - acc: 0.8293     \n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4243 - acc: 0.8300     \n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4269 - acc: 0.8286     \n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4244 - acc: 0.8287     \n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4230 - acc: 0.8300     \n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4220 - acc: 0.8317     \n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4231 - acc: 0.8318     \n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4240 - acc: 0.8296     \n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4252 - acc: 0.8290     \n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4213 - acc: 0.8317     \n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4225 - acc: 0.8326     \n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4272 - acc: 0.8307     \n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4241 - acc: 0.8290     \n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4255 - acc: 0.8292     \n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4223 - acc: 0.8299     \n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4236 - acc: 0.8318     \n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4259 - acc: 0.8310     \n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4235 - acc: 0.8318     \n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4240 - acc: 0.8319     \n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4219 - acc: 0.8301     \n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4249 - acc: 0.8287     \n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4234 - acc: 0.8314     \n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4255 - acc: 0.8317     \n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4235 - acc: 0.8297     \n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 8s - loss: 0.4255 - acc: 0.8304     \n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4226 - acc: 0.8292     \n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4246 - acc: 0.8301     \n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4239 - acc: 0.8278     \n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4209 - acc: 0.8314     \n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4260 - acc: 0.8311     \n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4252 - acc: 0.8314     \n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4239 - acc: 0.8306     \n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4245 - acc: 0.8293     \n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4243 - acc: 0.8296     \n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4235 - acc: 0.8306     \n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4224 - acc: 0.8293     \n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4269 - acc: 0.8308     \n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4193 - acc: 0.8322     \n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4254 - acc: 0.8308     \n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4258 - acc: 0.8303     \n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 2s - loss: 0.4268 - acc: 0.8306     \n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4254 - acc: 0.8296     \n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4251 - acc: 0.8283     \n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4245 - acc: 0.8322     \n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4199 - acc: 0.8324     \n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4194 - acc: 0.8308     \n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4279 - acc: 0.8307     \n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4239 - acc: 0.8310     \n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4242 - acc: 0.8299     \n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4263 - acc: 0.8297     \n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4224 - acc: 0.8325     \n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4222 - acc: 0.8319     \n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4195 - acc: 0.8308     \n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4217 - acc: 0.8328     \n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4241 - acc: 0.8306     \n",
      "630/800 [======================>.......] - ETA: 0sEpoch 1/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4947 - acc: 0.7965     \n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4398 - acc: 0.7967     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4357 - acc: 0.7967     \n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4334 - acc: 0.7967     \n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4305 - acc: 0.7967     \n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4338 - acc: 0.7967     \n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4325 - acc: 0.7967     \n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4293 - acc: 0.7967     \n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4318 - acc: 0.7985     \n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4309 - acc: 0.7997     \n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4283 - acc: 0.8247     \n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4283 - acc: 0.8233     \n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4276 - acc: 0.8249     \n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4292 - acc: 0.8267     \n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4284 - acc: 0.8250     \n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4305 - acc: 0.8272     \n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4290 - acc: 0.8274     \n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4268 - acc: 0.8287     \n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4297 - acc: 0.8271     \n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4290 - acc: 0.8256     \n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4298 - acc: 0.8268     \n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4297 - acc: 0.8268     \n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4269 - acc: 0.8268     \n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4294 - acc: 0.8300     \n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4291 - acc: 0.8290     \n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4268 - acc: 0.8312     \n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4263 - acc: 0.8310     \n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4305 - acc: 0.8318     \n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4260 - acc: 0.8297     \n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4262 - acc: 0.8299     \n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4283 - acc: 0.8321     \n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4285 - acc: 0.8318     \n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4287 - acc: 0.8301     \n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4266 - acc: 0.8321     \n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4289 - acc: 0.8337     \n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4239 - acc: 0.8312     \n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4275 - acc: 0.8312     \n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4273 - acc: 0.8321     \n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4289 - acc: 0.8297     \n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4301 - acc: 0.8285     \n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4313 - acc: 0.8299     \n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4224 - acc: 0.8301     \n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4255 - acc: 0.8333     \n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4310 - acc: 0.8310     \n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4263 - acc: 0.8322     \n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4266 - acc: 0.8332     \n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4238 - acc: 0.8321     \n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4267 - acc: 0.8326     \n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4286 - acc: 0.8310     \n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4277 - acc: 0.8314     \n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4274 - acc: 0.8308     \n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4272 - acc: 0.8312     \n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4245 - acc: 0.8321     \n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4307 - acc: 0.8318     \n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4237 - acc: 0.8325     \n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4273 - acc: 0.8310     \n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4260 - acc: 0.8319     \n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4282 - acc: 0.8326     \n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4250 - acc: 0.8321     \n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4222 - acc: 0.8347     \n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4265 - acc: 0.8308     \n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4245 - acc: 0.8299     \n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4246 - acc: 0.8340     \n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4271 - acc: 0.8328     \n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4268 - acc: 0.8356     \n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4280 - acc: 0.8310     \n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 8s - loss: 0.4217 - acc: 0.8307     \n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 8s - loss: 0.4268 - acc: 0.8326     \n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 8s - loss: 0.4238 - acc: 0.8325     \n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 9s - loss: 0.4221 - acc: 0.8336     \n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 8s - loss: 0.4301 - acc: 0.8314     - ETA: 0s - loss: 0.4314 - ac\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 8s - loss: 0.4271 - acc: 0.8324     \n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4246 - acc: 0.8342     \n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4263 - acc: 0.8321     \n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4283 - acc: 0.8322     \n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4303 - acc: 0.8331     \n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4257 - acc: 0.8339     \n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4286 - acc: 0.8310     \n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4274 - acc: 0.8339     \n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4243 - acc: 0.8335     \n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4278 - acc: 0.8331     \n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4269 - acc: 0.8328     \n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4267 - acc: 0.8329     \n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4255 - acc: 0.8318     \n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4266 - acc: 0.8321     \n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4293 - acc: 0.8322     \n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4280 - acc: 0.8321     \n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4254 - acc: 0.8336     \n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4263 - acc: 0.8333     \n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4305 - acc: 0.8312     \n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4257 - acc: 0.8306     \n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4292 - acc: 0.8342     \n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4247 - acc: 0.8318     \n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4262 - acc: 0.8325     \n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4250 - acc: 0.8342     \n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4247 - acc: 0.8324     \n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4219 - acc: 0.8319     \n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4298 - acc: 0.8332     \n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4233 - acc: 0.8321     \n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4269 - acc: 0.8344     \n",
      "690/800 [========================>.....] - ETA: 0sEpoch 1/100\n",
      "7200/7200 [==============================] - 9s - loss: 0.5008 - acc: 0.7950     \n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4418 - acc: 0.7956     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4356 - acc: 0.7956     \n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4338 - acc: 0.7956     \n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4333 - acc: 0.7956     \n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4337 - acc: 0.7956     \n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4329 - acc: 0.7956     \n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4319 - acc: 0.7993     \n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4344 - acc: 0.8154     \n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4319 - acc: 0.8187     \n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4298 - acc: 0.8244     \n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4298 - acc: 0.8260     \n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4315 - acc: 0.8268     \n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4333 - acc: 0.8268     \n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4328 - acc: 0.8264     \n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4297 - acc: 0.8300     \n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4311 - acc: 0.8269     \n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4308 - acc: 0.8290     \n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4279 - acc: 0.8282     \n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4243 - acc: 0.8275     \n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4314 - acc: 0.8278     \n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4317 - acc: 0.8300     \n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4268 - acc: 0.8304     \n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4314 - acc: 0.8304     \n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4263 - acc: 0.8312     \n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4312 - acc: 0.8294     \n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4298 - acc: 0.8328     \n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4292 - acc: 0.8308     \n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4297 - acc: 0.8304     \n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4297 - acc: 0.8312     \n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4322 - acc: 0.8303     \n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4256 - acc: 0.8318     \n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 8s - loss: 0.4295 - acc: 0.8308     \n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4258 - acc: 0.8324     \n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4267 - acc: 0.8304     \n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4307 - acc: 0.8318     \n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4247 - acc: 0.8340     \n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4266 - acc: 0.8342     \n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4257 - acc: 0.8350     \n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4305 - acc: 0.8311     \n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4264 - acc: 0.8332     \n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4287 - acc: 0.8326     \n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4285 - acc: 0.8317     \n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4293 - acc: 0.8301     \n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4261 - acc: 0.8314     \n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4251 - acc: 0.8310     \n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4256 - acc: 0.8322     \n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4307 - acc: 0.8319     \n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4260 - acc: 0.8324     \n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4298 - acc: 0.8322     \n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4274 - acc: 0.8321     \n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4284 - acc: 0.8319     \n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4283 - acc: 0.8325     \n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4272 - acc: 0.8311     \n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4255 - acc: 0.8347     \n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 2s - loss: 0.4261 - acc: 0.8297     \n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4310 - acc: 0.8317     \n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4228 - acc: 0.8337     \n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4258 - acc: 0.8329     \n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4273 - acc: 0.8339     \n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4285 - acc: 0.8315     \n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4235 - acc: 0.8324     \n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4284 - acc: 0.8333     \n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4273 - acc: 0.8315     \n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4274 - acc: 0.8312     \n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4290 - acc: 0.8333     \n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4258 - acc: 0.8333     \n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4279 - acc: 0.8321     \n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4298 - acc: 0.8311     \n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4295 - acc: 0.8325     \n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4307 - acc: 0.8329     \n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4263 - acc: 0.8279     \n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4295 - acc: 0.8311     \n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4294 - acc: 0.8322     \n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4249 - acc: 0.8343     \n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4270 - acc: 0.8317     \n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4231 - acc: 0.8321     \n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4260 - acc: 0.8340     \n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4227 - acc: 0.8324     \n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4263 - acc: 0.8326     \n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4257 - acc: 0.8312     \n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4281 - acc: 0.8347     \n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4270 - acc: 0.8321     \n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4294 - acc: 0.8315     \n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4237 - acc: 0.8336     \n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4256 - acc: 0.8317     \n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4235 - acc: 0.8337     \n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4299 - acc: 0.8336     \n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4273 - acc: 0.8325     \n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4270 - acc: 0.8318     \n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4251 - acc: 0.8332     \n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4257 - acc: 0.8329     \n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4276 - acc: 0.8300     \n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4285 - acc: 0.8343     \n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4268 - acc: 0.8332     \n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4275 - acc: 0.8325     \n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4263 - acc: 0.8325     \n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4242 - acc: 0.8331     \n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4292 - acc: 0.8322     \n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4234 - acc: 0.8315     \n",
      "530/800 [==================>...........] - ETA: 0sEpoch 1/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4995 - acc: 0.7965     \n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4384 - acc: 0.7975     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4391 - acc: 0.7975     \n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4338 - acc: 0.7975     \n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4347 - acc: 0.7975     \n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4370 - acc: 0.7975     \n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4375 - acc: 0.7975     \n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4347 - acc: 0.7975     \n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4367 - acc: 0.7975     \n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4334 - acc: 0.7975     \n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4317 - acc: 0.7975     \n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4319 - acc: 0.7975     \n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4349 - acc: 0.7975     \n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4359 - acc: 0.7975     \n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4340 - acc: 0.7975     \n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4355 - acc: 0.7975     \n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4336 - acc: 0.7975     \n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4334 - acc: 0.7975     \n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4331 - acc: 0.7975     \n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4357 - acc: 0.7975     \n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4319 - acc: 0.7975     \n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4318 - acc: 0.7975     \n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4339 - acc: 0.7975     \n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4316 - acc: 0.7975     \n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4341 - acc: 0.7975     \n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4305 - acc: 0.7975     \n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4303 - acc: 0.7975     \n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4351 - acc: 0.7975     \n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4342 - acc: 0.7975     \n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4324 - acc: 0.7975     \n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4339 - acc: 0.7975     \n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4331 - acc: 0.7975     \n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4315 - acc: 0.7975     \n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4305 - acc: 0.7975     \n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4301 - acc: 0.7975     \n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4345 - acc: 0.7975     \n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4280 - acc: 0.7975     \n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4255 - acc: 0.7975     \n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4320 - acc: 0.7975     \n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4315 - acc: 0.7975     \n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 2s - loss: 0.4336 - acc: 0.7975     \n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4323 - acc: 0.7975     \n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4286 - acc: 0.7975     \n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4290 - acc: 0.7975     \n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4291 - acc: 0.7975     \n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4266 - acc: 0.7975     \n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4321 - acc: 0.7975     \n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4319 - acc: 0.7975     \n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4298 - acc: 0.7975     \n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4286 - acc: 0.7975     \n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4324 - acc: 0.7975     \n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4302 - acc: 0.7975     \n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4303 - acc: 0.7975     \n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4261 - acc: 0.7975     \n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4293 - acc: 0.7975     \n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4297 - acc: 0.7975     \n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4258 - acc: 0.7975     \n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4272 - acc: 0.7975     \n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4316 - acc: 0.7975     \n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4298 - acc: 0.7975     \n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4326 - acc: 0.7975     \n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4314 - acc: 0.7975     \n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4292 - acc: 0.7975     \n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4320 - acc: 0.7975     \n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4335 - acc: 0.7975     \n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4301 - acc: 0.7975     \n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4283 - acc: 0.7975     \n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4310 - acc: 0.7975     \n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4283 - acc: 0.7975     \n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4280 - acc: 0.7975     \n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4290 - acc: 0.7975     \n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4261 - acc: 0.7975     \n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4311 - acc: 0.7975     \n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4298 - acc: 0.7975     \n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4268 - acc: 0.7975     \n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4329 - acc: 0.7975     \n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4313 - acc: 0.7975     \n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4297 - acc: 0.7975     \n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4303 - acc: 0.7975     \n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4335 - acc: 0.7975     \n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4303 - acc: 0.7975     \n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4256 - acc: 0.7975     \n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4296 - acc: 0.7975     \n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4287 - acc: 0.7975     \n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4298 - acc: 0.7975     \n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4290 - acc: 0.7975     \n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4276 - acc: 0.7975     \n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4296 - acc: 0.7975     \n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4339 - acc: 0.7975     \n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4296 - acc: 0.7975     \n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4258 - acc: 0.7975     \n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4274 - acc: 0.7975     \n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4300 - acc: 0.7975     \n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4284 - acc: 0.7975     \n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4306 - acc: 0.7975     \n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4254 - acc: 0.7975     \n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4329 - acc: 0.7975     \n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4330 - acc: 0.7975     \n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4303 - acc: 0.7975     \n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4303 - acc: 0.7975     \n",
      "560/800 [====================>.........] - ETA: 0sEpoch 1/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.5248 - acc: 0.7931     \n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4461 - acc: 0.7937     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4454 - acc: 0.7937     \n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4368 - acc: 0.7937     \n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4360 - acc: 0.7937     \n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4349 - acc: 0.7937     \n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4399 - acc: 0.7937     \n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4339 - acc: 0.7937     \n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4364 - acc: 0.7937     \n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4362 - acc: 0.7937     \n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4353 - acc: 0.7937     \n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4338 - acc: 0.7937     \n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4332 - acc: 0.7937     \n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4331 - acc: 0.8004     \n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4358 - acc: 0.7983     \n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4352 - acc: 0.8078     \n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4338 - acc: 0.8092     \n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4340 - acc: 0.8179     \n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4312 - acc: 0.8174     \n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4338 - acc: 0.8224     \n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4314 - acc: 0.8224     \n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4364 - acc: 0.8232     \n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4303 - acc: 0.8228     \n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4320 - acc: 0.8256     \n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4341 - acc: 0.8228     \n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 2s - loss: 0.4330 - acc: 0.8231     \n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4378 - acc: 0.8194     \n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4332 - acc: 0.8211     \n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4341 - acc: 0.8187     \n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4303 - acc: 0.8247     \n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4290 - acc: 0.8218     \n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4344 - acc: 0.8256     \n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4332 - acc: 0.8235     \n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4356 - acc: 0.8228     \n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4304 - acc: 0.8258     \n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4346 - acc: 0.8239     \n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4342 - acc: 0.8211     \n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4307 - acc: 0.8233     \n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4323 - acc: 0.8226     \n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4291 - acc: 0.8251     \n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4322 - acc: 0.8244     \n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4299 - acc: 0.8264     \n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4304 - acc: 0.8232     \n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4312 - acc: 0.8243     \n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4346 - acc: 0.8242     \n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4331 - acc: 0.8276     \n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4296 - acc: 0.8251     \n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4346 - acc: 0.8226     \n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4300 - acc: 0.8257     \n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4345 - acc: 0.8226     \n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4321 - acc: 0.8244     \n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4328 - acc: 0.8251     \n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4305 - acc: 0.8275     \n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4336 - acc: 0.8231     \n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 8s - loss: 0.4321 - acc: 0.8215     \n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 8s - loss: 0.4319 - acc: 0.8251     \n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4332 - acc: 0.8225     \n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4301 - acc: 0.8278     \n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4337 - acc: 0.8222     \n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4307 - acc: 0.8258     \n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4331 - acc: 0.8217     \n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4288 - acc: 0.8260     \n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4313 - acc: 0.8237     \n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4318 - acc: 0.8264     \n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4280 - acc: 0.8258     \n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4271 - acc: 0.8254     \n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4288 - acc: 0.8275     \n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4301 - acc: 0.8271     \n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4323 - acc: 0.8265     \n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4298 - acc: 0.8283     \n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4303 - acc: 0.8262     \n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4297 - acc: 0.8254     \n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4320 - acc: 0.8268     \n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4280 - acc: 0.8224     \n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4324 - acc: 0.8297     \n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4331 - acc: 0.8257     \n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4319 - acc: 0.8282     \n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4293 - acc: 0.8249     \n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4341 - acc: 0.8290     \n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4317 - acc: 0.8231     \n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4305 - acc: 0.8256     \n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4308 - acc: 0.8293     \n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4267 - acc: 0.8282     \n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4321 - acc: 0.8282     \n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4310 - acc: 0.8278     \n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4314 - acc: 0.8253     \n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4306 - acc: 0.8287     \n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4328 - acc: 0.8265     \n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4299 - acc: 0.8271     \n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4313 - acc: 0.8264     \n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4322 - acc: 0.8265     \n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4298 - acc: 0.8287     \n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4304 - acc: 0.8279     \n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4306 - acc: 0.8294     \n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4270 - acc: 0.8276     \n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4335 - acc: 0.8257     \n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4308 - acc: 0.8249     \n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4333 - acc: 0.8237     \n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4309 - acc: 0.8247     \n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4313 - acc: 0.8268     \n",
      "720/800 [==========================>...] - ETA: 0sEpoch 1/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.5209 - acc: 0.7925     \n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4515 - acc: 0.7944     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4477 - acc: 0.7944     \n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4451 - acc: 0.7944     \n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4455 - acc: 0.7944     \n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4464 - acc: 0.7944     \n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4453 - acc: 0.7944     \n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4468 - acc: 0.7944     \n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4449 - acc: 0.7944     \n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4416 - acc: 0.7944     \n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 4s - loss: 0.4423 - acc: 0.7944     \n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4423 - acc: 0.7944     \n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4450 - acc: 0.7944     \n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4431 - acc: 0.7944     \n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4399 - acc: 0.7944     \n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4417 - acc: 0.7944     \n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4457 - acc: 0.7944     \n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4429 - acc: 0.7944     \n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4452 - acc: 0.7944     \n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4410 - acc: 0.7944     \n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4429 - acc: 0.7944     \n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4406 - acc: 0.7944     \n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4439 - acc: 0.7944     \n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4431 - acc: 0.7944     \n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4410 - acc: 0.7944     \n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4381 - acc: 0.7944     \n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4422 - acc: 0.7944     \n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4414 - acc: 0.7944     \n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4438 - acc: 0.7944     \n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4387 - acc: 0.7944     \n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4396 - acc: 0.7944     \n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4394 - acc: 0.7944     \n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4407 - acc: 0.7944     \n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4428 - acc: 0.7944     \n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4378 - acc: 0.7944     \n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4372 - acc: 0.7944     \n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4395 - acc: 0.7944     \n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4378 - acc: 0.7944     \n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4410 - acc: 0.7944     \n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4379 - acc: 0.7944     \n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4430 - acc: 0.7944     \n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4383 - acc: 0.7944     \n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4383 - acc: 0.7944     \n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4401 - acc: 0.7944     \n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4382 - acc: 0.7944     \n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4393 - acc: 0.7944     \n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4376 - acc: 0.7944     \n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4372 - acc: 0.7944     \n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4398 - acc: 0.7944     \n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4404 - acc: 0.7944     \n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4396 - acc: 0.7944     \n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4359 - acc: 0.7944     \n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4369 - acc: 0.7944     \n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4424 - acc: 0.7944     \n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4356 - acc: 0.7944     \n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - ETA: 0s - loss: 0.4400 - acc: 0.794 - 6s - loss: 0.4399 - acc: 0.7944     \n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4356 - acc: 0.7944     \n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4388 - acc: 0.7944     \n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4396 - acc: 0.7944     \n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4375 - acc: 0.7944     \n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4378 - acc: 0.7944     \n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4369 - acc: 0.7944     \n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4389 - acc: 0.7944     \n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4399 - acc: 0.7944     \n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4377 - acc: 0.7944     \n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4345 - acc: 0.7944     \n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4376 - acc: 0.7944     \n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4363 - acc: 0.7944     \n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4435 - acc: 0.7944     \n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4423 - acc: 0.7944     \n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4365 - acc: 0.7944     \n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4380 - acc: 0.7944     \n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4401 - acc: 0.7944     \n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4338 - acc: 0.7944     \n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4382 - acc: 0.7944     \n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4349 - acc: 0.7944     \n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4354 - acc: 0.7944     \n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4406 - acc: 0.7944     \n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4354 - acc: 0.7944     \n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4385 - acc: 0.7944     \n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4347 - acc: 0.7944     \n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4382 - acc: 0.7944     \n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4363 - acc: 0.7944     \n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4383 - acc: 0.7944     \n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4408 - acc: 0.7944     \n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4353 - acc: 0.7944     \n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4342 - acc: 0.7944     \n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4367 - acc: 0.7944     \n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4388 - acc: 0.7944     \n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4362 - acc: 0.7944     \n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4403 - acc: 0.7944     \n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4356 - acc: 0.7944     \n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4352 - acc: 0.7944     \n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4345 - acc: 0.7944     \n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4346 - acc: 0.7944     \n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 2s - loss: 0.4364 - acc: 0.7944     \n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4343 - acc: 0.7944     \n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4380 - acc: 0.7944     \n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4350 - acc: 0.7944     \n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4413 - acc: 0.7944     \n",
      "690/800 [========================>.....] - ETA: 0sEpoch 1/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.5016 - acc: 0.7965     \n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4437 - acc: 0.7969     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4358 - acc: 0.7969     \n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4358 - acc: 0.7969     \n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4348 - acc: 0.7969     \n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4330 - acc: 0.7969     \n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4308 - acc: 0.7969     \n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4329 - acc: 0.7969     \n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4331 - acc: 0.7969     \n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4343 - acc: 0.7969     \n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4303 - acc: 0.7969     \n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4334 - acc: 0.7969     \n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4319 - acc: 0.7969     \n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4327 - acc: 0.7969     \n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4286 - acc: 0.7969     \n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4310 - acc: 0.7969     \n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4328 - acc: 0.7969     \n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4314 - acc: 0.7969     \n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4316 - acc: 0.7969     \n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4333 - acc: 0.7969     \n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4318 - acc: 0.7969     \n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4335 - acc: 0.7969     \n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4323 - acc: 0.7969     \n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4259 - acc: 0.7969     \n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4279 - acc: 0.7969     \n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4294 - acc: 0.7969     \n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4303 - acc: 0.7969     \n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4322 - acc: 0.7969     \n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4301 - acc: 0.7969     \n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4282 - acc: 0.7969     \n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4278 - acc: 0.7969     \n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4303 - acc: 0.7969     \n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4289 - acc: 0.7969     \n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4284 - acc: 0.7969     \n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4321 - acc: 0.7972     \n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4286 - acc: 0.7969     \n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4328 - acc: 0.8007     \n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4275 - acc: 0.7969     \n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4291 - acc: 0.7983     \n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4285 - acc: 0.7969     \n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4283 - acc: 0.7976     \n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4290 - acc: 0.8046     \n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4305 - acc: 0.8026     \n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4266 - acc: 0.8079     \n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4275 - acc: 0.8144     \n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4269 - acc: 0.8189     \n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4317 - acc: 0.8140     \n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4313 - acc: 0.8050     \n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4296 - acc: 0.8111     \n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4314 - acc: 0.7972     \n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4304 - acc: 0.7979     \n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4276 - acc: 0.8019     \n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4282 - acc: 0.8024     \n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4307 - acc: 0.7969     \n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4303 - acc: 0.7969     \n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4312 - acc: 0.7969     \n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4330 - acc: 0.7969     \n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4310 - acc: 0.7969     \n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4279 - acc: 0.7969     \n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4266 - acc: 0.7969     \n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4293 - acc: 0.7969     \n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4268 - acc: 0.7969     \n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4290 - acc: 0.8136     \n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4320 - acc: 0.7993     \n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4278 - acc: 0.8068     \n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4255 - acc: 0.8056     \n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4311 - acc: 0.8065     \n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4295 - acc: 0.8086     \n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4288 - acc: 0.7999     \n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4291 - acc: 0.8082     \n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4233 - acc: 0.8129     \n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4339 - acc: 0.8108     \n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4282 - acc: 0.8006     \n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4279 - acc: 0.8067     \n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4297 - acc: 0.7976     \n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4269 - acc: 0.7989     \n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4284 - acc: 0.8164     \n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4303 - acc: 0.8125     \n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4277 - acc: 0.8072     \n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4309 - acc: 0.7985     \n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 2s - loss: 0.4276 - acc: 0.7996     \n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4282 - acc: 0.8028     \n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4277 - acc: 0.7992     \n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4295 - acc: 0.7969     \n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4267 - acc: 0.7981     \n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4307 - acc: 0.7969     \n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4273 - acc: 0.8024     \n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4307 - acc: 0.7969     \n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4294 - acc: 0.7969     \n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4272 - acc: 0.7969     \n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4283 - acc: 0.7969     \n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4254 - acc: 0.7974     \n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4243 - acc: 0.8126     \n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4280 - acc: 0.8126     \n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4249 - acc: 0.8178     \n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4243 - acc: 0.8214     \n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4292 - acc: 0.8251     \n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4253 - acc: 0.8254     \n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4288 - acc: 0.8190     \n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4280 - acc: 0.7993     \n",
      "590/800 [=====================>........] - ETA: 0sEpoch 1/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4956 - acc: 0.7961     \n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4415 - acc: 0.7962     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4402 - acc: 0.7962     \n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4352 - acc: 0.7962     \n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4335 - acc: 0.7962     \n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4311 - acc: 0.7962     \n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4280 - acc: 0.7962     \n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4291 - acc: 0.7962     \n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4277 - acc: 0.7962     \n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4263 - acc: 0.7962     \n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4301 - acc: 0.7974     \n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4330 - acc: 0.7957     \n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4294 - acc: 0.8044     \n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4272 - acc: 0.8186     \n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4272 - acc: 0.8265     \n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4273 - acc: 0.8260     \n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4306 - acc: 0.8268     \n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4261 - acc: 0.8271     \n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4318 - acc: 0.8260     \n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4255 - acc: 0.8262     \n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4295 - acc: 0.8246     \n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4242 - acc: 0.8293     \n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4257 - acc: 0.8278     \n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4262 - acc: 0.8268     \n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4261 - acc: 0.8274     \n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4271 - acc: 0.8281     \n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4246 - acc: 0.8301     \n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4266 - acc: 0.8293     \n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4270 - acc: 0.8281     \n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4272 - acc: 0.8285     \n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4275 - acc: 0.8281     \n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4312 - acc: 0.8278     \n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4266 - acc: 0.8281     \n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4281 - acc: 0.8293     \n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4290 - acc: 0.8281     \n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4261 - acc: 0.8290     \n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4253 - acc: 0.8281     \n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4243 - acc: 0.8279     \n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4268 - acc: 0.8275     \n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4279 - acc: 0.8303     \n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4241 - acc: 0.8264     \n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4284 - acc: 0.8283     \n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4257 - acc: 0.8290     \n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4221 - acc: 0.8300     \n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4284 - acc: 0.8317     \n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4284 - acc: 0.8310     \n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4235 - acc: 0.8257     \n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4247 - acc: 0.8290     \n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4262 - acc: 0.8278     \n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4244 - acc: 0.8297     \n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4251 - acc: 0.8318     \n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4310 - acc: 0.8292     \n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4264 - acc: 0.8268     \n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4287 - acc: 0.8318     \n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4267 - acc: 0.8307     \n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4284 - acc: 0.8283     \n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4287 - acc: 0.8269     \n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4278 - acc: 0.8276     \n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4263 - acc: 0.8293     \n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4245 - acc: 0.8310     \n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4233 - acc: 0.8293     \n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4277 - acc: 0.8299     \n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4296 - acc: 0.8275     \n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 7s - loss: 0.4273 - acc: 0.8292     \n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4253 - acc: 0.8290     \n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 5s - loss: 0.4233 - acc: 0.8303     \n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4258 - acc: 0.8283     \n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4319 - acc: 0.8274     \n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4250 - acc: 0.8303     \n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4240 - acc: 0.8297     \n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4290 - acc: 0.8279     \n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4251 - acc: 0.8293     \n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4291 - acc: 0.8294     \n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4244 - acc: 0.8286     \n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4239 - acc: 0.8287     \n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4234 - acc: 0.8308     \n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4254 - acc: 0.8301     \n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4283 - acc: 0.8285     \n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4287 - acc: 0.8278     \n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4228 - acc: 0.8301     \n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4244 - acc: 0.8297     \n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4232 - acc: 0.8296     \n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4278 - acc: 0.8289     \n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4254 - acc: 0.8306     \n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4269 - acc: 0.8267     \n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4265 - acc: 0.8315     \n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4277 - acc: 0.8286     \n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4336 - acc: 0.8283     \n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4254 - acc: 0.8282     \n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4264 - acc: 0.8314     \n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4299 - acc: 0.8276     \n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4303 - acc: 0.8306     \n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4264 - acc: 0.8260     \n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4271 - acc: 0.8307     \n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4254 - acc: 0.8283     \n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4265 - acc: 0.8308     \n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4265 - acc: 0.8292     \n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4281 - acc: 0.8317     \n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4259 - acc: 0.8274     \n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4256 - acc: 0.8292     \n",
      "460/800 [================>.............] - ETA: 0s Epoch 1/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.5132 - acc: 0.7956     \n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4428 - acc: 0.7957     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4366 - acc: 0.7957     \n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4362 - acc: 0.7957     \n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4310 - acc: 0.7957     \n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4318 - acc: 0.7957     \n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4322 - acc: 0.7957     \n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4281 - acc: 0.7957     - ETA: 0s - loss: 0.4314 - acc: 0.\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4276 - acc: 0.7957     \n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4298 - acc: 0.8100     \n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4281 - acc: 0.8181     \n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4290 - acc: 0.8271     \n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4296 - acc: 0.8279     \n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4283 - acc: 0.8289     \n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4259 - acc: 0.8286     \n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4285 - acc: 0.8306     \n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4286 - acc: 0.8290     \n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4314 - acc: 0.8307     \n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4321 - acc: 0.8300     \n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4316 - acc: 0.8322     \n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4268 - acc: 0.8311     \n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4275 - acc: 0.8310     \n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4285 - acc: 0.8303     \n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4313 - acc: 0.8299     \n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4295 - acc: 0.8294     \n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4292 - acc: 0.8312     \n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4239 - acc: 0.8321     \n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4244 - acc: 0.8307     \n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4255 - acc: 0.8339     \n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4262 - acc: 0.8331     \n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4288 - acc: 0.8306     \n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4247 - acc: 0.8324     \n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4211 - acc: 0.8336     \n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4223 - acc: 0.8335     \n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4212 - acc: 0.8318     \n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4243 - acc: 0.8293     \n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4225 - acc: 0.8332     \n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4252 - acc: 0.8335     \n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4253 - acc: 0.8336     \n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4303 - acc: 0.8307     \n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4287 - acc: 0.8326     \n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4248 - acc: 0.8331     \n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4256 - acc: 0.8344     \n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4244 - acc: 0.8347     \n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4271 - acc: 0.8324     \n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4261 - acc: 0.8332     \n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4275 - acc: 0.8333     \n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4238 - acc: 0.8335     \n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4240 - acc: 0.8310     \n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4284 - acc: 0.8314     \n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 2s - loss: 0.4237 - acc: 0.8322     \n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4257 - acc: 0.8310     \n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4268 - acc: 0.8329     \n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4236 - acc: 0.8328     \n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4273 - acc: 0.8353     \n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4249 - acc: 0.8349     \n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4264 - acc: 0.8333     \n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4234 - acc: 0.8335     \n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4281 - acc: 0.8332     \n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4254 - acc: 0.8307     \n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4204 - acc: 0.8318     \n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4242 - acc: 0.8324     \n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4220 - acc: 0.8339     \n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4233 - acc: 0.8315     \n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4267 - acc: 0.8325     \n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4254 - acc: 0.8310     \n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4232 - acc: 0.8325     \n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4228 - acc: 0.8335     \n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4264 - acc: 0.8326     \n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4256 - acc: 0.8328     \n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4257 - acc: 0.8322     \n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4247 - acc: 0.8317     \n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4254 - acc: 0.8331     \n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4235 - acc: 0.8329     \n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4233 - acc: 0.8335     \n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4254 - acc: 0.8314     \n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4267 - acc: 0.8326     \n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4234 - acc: 0.8332     \n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4234 - acc: 0.8319     \n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4206 - acc: 0.8349     \n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4242 - acc: 0.8340     - ETA: 1\n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4218 - acc: 0.8311     \n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4254 - acc: 0.8326     \n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4186 - acc: 0.8322     \n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4250 - acc: 0.8331     \n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4233 - acc: 0.8335     \n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4178 - acc: 0.8369     \n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4244 - acc: 0.8332     \n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4220 - acc: 0.8361     \n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4222 - acc: 0.8357     \n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4205 - acc: 0.8337     \n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4240 - acc: 0.8319     \n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4227 - acc: 0.8342     \n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4272 - acc: 0.8340     \n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4216 - acc: 0.8331     \n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4224 - acc: 0.8339     \n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4235 - acc: 0.8362     \n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4219 - acc: 0.8322     \n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4210 - acc: 0.8343     \n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4229 - acc: 0.8360     \n",
      "450/800 [===============>..............] - ETA: 0s Epoch 1/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.5056 - acc: 0.7954     \n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4478 - acc: 0.7961     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4464 - acc: 0.7961     \n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4417 - acc: 0.7961     \n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4438 - acc: 0.7961     \n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4380 - acc: 0.7961     \n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4366 - acc: 0.7961     \n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4377 - acc: 0.7961     \n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4408 - acc: 0.7961     \n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4375 - acc: 0.7961     \n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4343 - acc: 0.7961     \n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 3s - loss: 0.4358 - acc: 0.7961     \n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4313 - acc: 0.7961     \n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4348 - acc: 0.7961     \n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4339 - acc: 0.7961     \n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4314 - acc: 0.7961     \n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4303 - acc: 0.8010     \n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4268 - acc: 0.8137     \n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4239 - acc: 0.8219     \n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4194 - acc: 0.8210     \n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4167 - acc: 0.8250     \n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4159 - acc: 0.8278     \n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4152 - acc: 0.8264     \n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4149 - acc: 0.8324     - ETA: 1s - loss: \n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4101 - acc: 0.8274     \n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4082 - acc: 0.8296     \n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4095 - acc: 0.8314     \n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4079 - acc: 0.8364     \n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4055 - acc: 0.8292     \n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4075 - acc: 0.8340     \n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4071 - acc: 0.8346     \n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4061 - acc: 0.8325     \n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4054 - acc: 0.8322     - ETA: \n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4015 - acc: 0.8351     \n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4020 - acc: 0.8361     \n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s - loss: 0.3997 - acc: 0.8362     \n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3966 - acc: 0.8378     \n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4075 - acc: 0.8301     \n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4036 - acc: 0.8339     \n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4061 - acc: 0.8317     \n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4020 - acc: 0.8276     \n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4006 - acc: 0.8332     \n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4027 - acc: 0.8318     \n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4038 - acc: 0.8346     \n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3995 - acc: 0.8396     \n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3997 - acc: 0.8394     \n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4009 - acc: 0.8390     \n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4012 - acc: 0.8325     \n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3976 - acc: 0.8362     \n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4044 - acc: 0.8337     \n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4040 - acc: 0.8321     \n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4032 - acc: 0.8404     \n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4046 - acc: 0.8346     \n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4039 - acc: 0.8324     \n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4045 - acc: 0.8325     \n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4017 - acc: 0.8356     \n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4033 - acc: 0.8353     \n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4044 - acc: 0.8337     \n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3992 - acc: 0.8386     \n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4012 - acc: 0.8356     \n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4010 - acc: 0.8356     \n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3987 - acc: 0.8408     \n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4003 - acc: 0.8340     \n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3978 - acc: 0.8378     \n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4042 - acc: 0.8340     \n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3980 - acc: 0.8385     \n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4009 - acc: 0.8376     \n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3966 - acc: 0.8386     \n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4034 - acc: 0.8354     \n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3976 - acc: 0.8368     \n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4028 - acc: 0.8379     \n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4009 - acc: 0.8371     \n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4021 - acc: 0.8365     \n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4015 - acc: 0.8383     \n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3978 - acc: 0.8403     \n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4005 - acc: 0.8376     \n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3991 - acc: 0.8360     \n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4004 - acc: 0.8403     \n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4010 - acc: 0.8383     \n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3954 - acc: 0.8415     \n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3973 - acc: 0.8387     \n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3943 - acc: 0.8442     \n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4014 - acc: 0.8410     \n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3982 - acc: 0.8397     \n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4040 - acc: 0.8335     \n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3972 - acc: 0.8408     \n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4006 - acc: 0.8375     \n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3997 - acc: 0.8387     \n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3985 - acc: 0.8390     \n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4036 - acc: 0.8346     \n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3957 - acc: 0.8381     \n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3978 - acc: 0.8362     \n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4019 - acc: 0.8340     \n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4018 - acc: 0.8343     \n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3996 - acc: 0.8381     \n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.4045 - acc: 0.8354     \n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s - loss: 0.3985 - acc: 0.8389     \n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3976 - acc: 0.8404     \n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4029 - acc: 0.8368     \n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4002 - acc: 0.8354     \n",
      "770/800 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
